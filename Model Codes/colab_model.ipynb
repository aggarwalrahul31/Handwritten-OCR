{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Coz7f0oBT-RM",
        "colab_type": "code",
        "outputId": "fb7621bb-d2c3-47bf-d651-ff1705f3b9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import csv\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEkrD43MUGYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# from keras.applications import densenet\n",
        "# from keras.models import Sequential, Model, load_model\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "# from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "# from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
        "# from keras import regularizers\n",
        "# from keras import backend as K\n",
        "\n",
        "\n",
        "# # Import Keras libraries\n",
        "# import keras\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten\n",
        "# from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtNGXrvTkf7y",
        "colab_type": "code",
        "outputId": "6ed91e01-d8e7-4dc7-d84a-03b087db16d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.applications import densenet\n",
        "from tensorflow.python.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
        "from tensorflow.python.keras import regularizers\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "# Import Keras libraries\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWGJmwMNUGb8",
        "colab_type": "code",
        "outputId": "34666faf-b0c3-40d2-d53e-e28a3dd730be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaLiynF5dGvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df1=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/train/train_letters.csv\")\n",
        "# df2=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/train/train_digits.csv\")\n",
        "# df3=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/train/space_19_1_78.csv\")\n",
        "# df4=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/train/space_19_2_78.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46BmR4lEG65H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train1=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/train/train_letters.csv\")\n",
        "# train2=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/train/train_digits.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubWAAW8nHNUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_train1=df1.iloc[:,:1].values\n",
        "# y_train1=y_train1-65\n",
        "# df1[\"0\"]=y_train1\n",
        "\n",
        "# y_train2=df2.iloc[:,:1].values\n",
        "# y_train2=y_train2+26\n",
        "# df2[\"0\"]=y_train2\n",
        "\n",
        "# y_train3=df3.iloc[:,:1].values\n",
        "# y_train3=y_train3+36\n",
        "# df3[\"0\"]=y_train3\n",
        "\n",
        "# y_train4=df4.iloc[:,:1].values\n",
        "# y_train4=y_train4+36\n",
        "# df4[\"0\"]=y_train4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8GjBUXbHPd2",
        "colab_type": "code",
        "outputId": "d090db9d-4add-49da-9702-1249a19c3953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# df=pd.DataFrame()\n",
        "# df=pd.concat([df1,df2,df3,df4,df3,df4])\n",
        "# print(df.shape)\n",
        "\n",
        "# df.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/train/train_letters_digits_space_78.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(119540, 6085)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFXTgMa84r89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test1=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/test/test_letters.csv\")\n",
        "# test2=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/test/test_digits.csv\")\n",
        "# test3=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/test/space_20_1_78.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAlfpLct5IM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_test1=test1.iloc[:,:1].values\n",
        "# y_test1=y_test1-65\n",
        "# test1[\"0\"]=y_test1\n",
        "\n",
        "# y_test2=test2.iloc[:,:1].values\n",
        "# y_test2=y_test2+26\n",
        "# test2[\"0\"]=y_test2\n",
        "\n",
        "# y_test3=test3.iloc[:,:1].values\n",
        "# y_test3=y_test3+36\n",
        "# test3[\"0\"]=y_test3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-z25W4k5iRS",
        "colab_type": "code",
        "outputId": "592b50db-591c-48d5-dd3e-192130ea284e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# df=pd.DataFrame()\n",
        "# df=pd.concat([test1,test2,test3])\n",
        "# print(df.shape)\n",
        "\n",
        "# df.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/test/test_letters_digits_space_78.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10359, 6085)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cegcQINoUGfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/train/train_letters_space_78.csv\")\n",
        "test=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/results/test/test_letters_space_78.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Cklvugwb1W",
        "colab_type": "text"
      },
      "source": [
        "#### Train Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rdvK1gQUGm2",
        "colab_type": "code",
        "outputId": "dcc59729-39a5-41f6-f3a2-5b457bb19291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# We have grayscale images, so while loading the images we will keep grayscale=True, if you have RGB images, you should set grayscale as False\n",
        "train_image = []\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "  im_buf = train.values[i][1:]\n",
        "  im_array = np.int8(np.reshape(im_buf, (78, 78))) \n",
        "  #img = image.load_img(train.iloc[:,1:].as_matrix().astype('str'), target_size=(64,64,1), color_mode='grayscale')\n",
        "  img = image.img_to_array(im_array)\n",
        "  img = img/255\n",
        "  train_image.append(img)\n",
        "X_train = np.array(train_image)\n",
        "X_train = np.repeat(X_train, 3, -1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 94829/94829 [00:19<00:00, 4774.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF4CmjbllOey",
        "colab_type": "code",
        "outputId": "d7db2e6c-aa51-4ca8-b3fb-1ce0f101d10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "train.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>6045</th>\n",
              "      <th>6046</th>\n",
              "      <th>6047</th>\n",
              "      <th>6048</th>\n",
              "      <th>6049</th>\n",
              "      <th>6050</th>\n",
              "      <th>6051</th>\n",
              "      <th>6052</th>\n",
              "      <th>6053</th>\n",
              "      <th>6054</th>\n",
              "      <th>6055</th>\n",
              "      <th>6056</th>\n",
              "      <th>6057</th>\n",
              "      <th>6058</th>\n",
              "      <th>6059</th>\n",
              "      <th>6060</th>\n",
              "      <th>6061</th>\n",
              "      <th>6062</th>\n",
              "      <th>6063</th>\n",
              "      <th>6064</th>\n",
              "      <th>6065</th>\n",
              "      <th>6066</th>\n",
              "      <th>6067</th>\n",
              "      <th>6068</th>\n",
              "      <th>6069</th>\n",
              "      <th>6070</th>\n",
              "      <th>6071</th>\n",
              "      <th>6072</th>\n",
              "      <th>6073</th>\n",
              "      <th>6074</th>\n",
              "      <th>6075</th>\n",
              "      <th>6076</th>\n",
              "      <th>6077</th>\n",
              "      <th>6078</th>\n",
              "      <th>6079</th>\n",
              "      <th>6080</th>\n",
              "      <th>6081</th>\n",
              "      <th>6082</th>\n",
              "      <th>6083</th>\n",
              "      <th>6084</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119535</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119536</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119537</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119538</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119539</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 6085 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0  1  2  3  4  5  6  7  ...  6077  6078  6079  6080  6081  6082  6083  6084\n",
              "119535  36  0  0  0  0  0  0  0  ...     0     0     0     0     0     0     0     0\n",
              "119536  36  0  0  0  0  0  0  0  ...     0     0     0     0     0     0     0     0\n",
              "119537  36  0  0  0  0  0  0  0  ...     0     0     0     0     0     0     0     0\n",
              "119538  36  0  0  0  0  0  0  0  ...     0     0     0     0     0     0     0     0\n",
              "119539  36  0  0  0  0  0  0  0  ...     0     0     0     0     0     0     0     0\n",
              "\n",
              "[5 rows x 6085 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb-0phViUGow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=train.iloc[:,:1].values\n",
        "#y_train=y_train-65\n",
        "y_train = to_categorical(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBHFbup3whSg",
        "colab_type": "text"
      },
      "source": [
        "#### Test Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXFXLtrxUGrx",
        "colab_type": "code",
        "outputId": "d809772e-495f-46b4-d8bd-25528761e2bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# We have grayscale images, so while loading the images we will keep grayscale=True, if you have RGB images, you should set grayscale as False\n",
        "test_image = []\n",
        "for i in tqdm(range(test.shape[0])):\n",
        "  im_buf = test.values[i][1:]\n",
        "  im_array = np.int8(np.reshape(im_buf, (78, 78))) \n",
        "  #img = image.load_img(train.iloc[:,1:].as_matrix().astype('str'), target_size=(64,64,1), color_mode='grayscale')\n",
        "  img = image.img_to_array(im_array)\n",
        "  img = img/255\n",
        "  test_image.append(img)\n",
        "X_test = np.array(test_image)\n",
        "X_test = np.repeat(X_test, 3, -1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8064/8064 [00:02<00:00, 3753.24it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knJyDJGMUGuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test=test.iloc[:,:1].values\n",
        "#y_test=y_test-65\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwm79y2ewkY4",
        "colab_type": "text"
      },
      "source": [
        "#### Model Builiding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFL1ELrMVdU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import applications\n",
        "\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZIp_L0ymav4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    #base_model = densenet.DenseNet121(input_shape=(img_width, img_height, 3),\n",
        "                                     #weights='../input/full-keras-pretrained-no-top/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                                     #include_top=False,\n",
        "                                     #pooling='avg')\n",
        "    base_model=applications.inception_resnet_v2.InceptionResNetV2(weights= None, include_top=False, input_shape= (78,78,3))\n",
        "    for layer in base_model.layers:\n",
        "          layer.trainable = True\n",
        "\n",
        "#     x = base_model.output\n",
        "#     x = Dense(1000, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
        "#     x = Activation('relu')(x)\n",
        "#     x = Dense(500, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
        "#     x = Activation('relu')(x)\n",
        "#     predictions = Dense(n_classes, activation='softmax')(x)\n",
        "#     model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    x = base_model.output\n",
        "    # x = Dense(128, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
        "    # x = Activation('relu')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.40)(x)\n",
        "    predictions = Dense(units=27, activation= 'softmax')(x)\n",
        "    model = Model(inputs = base_model.input, outputs = predictions)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI7HUQxCmasP",
        "colab_type": "code",
        "outputId": "534fc2d0-d502-4b16-a27f-3940710a2838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc','mse'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 78, 78, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 38, 38, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 38, 38, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 38, 38, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 36, 36, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 36, 36, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 36, 36, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 36, 36, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 36, 36, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 36, 36, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 17, 17, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 17, 17, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 17, 17, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 17, 17, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 15, 15, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 15, 15, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 15, 15, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 192)    0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 7, 7, 64)     12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 7, 7, 64)     192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 7, 7, 64)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 7, 7, 48)     9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 7, 7, 96)     55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 7, 7, 48)     144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 7, 7, 96)     288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 7, 7, 48)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 7, 7, 96)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 7, 7, 192)    0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 7, 7, 96)     18432       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 7, 7, 64)     76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 7, 7, 96)     82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 7, 7, 64)     12288       average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 7, 7, 96)     288         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 7, 7, 64)     192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 7, 7, 96)     288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 7, 7, 64)     192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 7, 7, 96)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 7, 7, 64)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 7, 7, 96)     0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 7, 7, 64)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed_5b (Concatenate)          (None, 7, 7, 320)    0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 7, 7, 32)     10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 7, 7, 32)     96          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 7, 7, 32)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 7, 7, 32)     10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 7, 7, 48)     13824       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 7, 7, 32)     96          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 7, 7, 48)     144         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 7, 7, 32)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 7, 7, 48)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 7, 7, 32)     10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 7, 7, 32)     9216        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 7, 7, 64)     27648       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 7, 7, 32)     96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 7, 7, 32)     96          conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 7, 7, 64)     192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 7, 7, 32)     0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 7, 7, 32)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 7, 7, 64)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_mixed (Concatenate)   (None, 7, 7, 128)    0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_conv (Conv2D)         (None, 7, 7, 320)    41280       block35_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_1 (Lambda)              (None, 7, 7, 320)    0           mixed_5b[0][0]                   \n",
            "                                                                 block35_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_ac (Activation)       (None, 7, 7, 320)    0           block35_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 7, 7, 32)     10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 7, 7, 32)     96          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 7, 7, 32)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 7, 7, 32)     10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 7, 7, 48)     13824       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 7, 7, 32)     96          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 7, 7, 48)     144         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 7, 7, 32)     0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 7, 7, 48)     0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 7, 7, 32)     10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 7, 7, 32)     9216        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 7, 7, 64)     27648       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 7, 7, 32)     96          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 7, 7, 32)     96          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 7, 7, 64)     192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 7, 7, 32)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 7, 7, 32)     0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 7, 7, 64)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_mixed (Concatenate)   (None, 7, 7, 128)    0           activation_18[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_conv (Conv2D)         (None, 7, 7, 320)    41280       block35_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_2 (Lambda)              (None, 7, 7, 320)    0           block35_1_ac[0][0]               \n",
            "                                                                 block35_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_ac (Activation)       (None, 7, 7, 320)    0           block35_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 7, 7, 32)     10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 7, 7, 32)     96          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 7, 7, 32)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 7, 7, 32)     10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 7, 7, 48)     13824       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 7, 7, 32)     96          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 7, 7, 48)     144         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 7, 7, 32)     0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 7, 7, 48)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 7, 7, 32)     10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 32)     9216        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 64)     27648       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 7, 7, 32)     96          conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 32)     96          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 64)     192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 7, 7, 32)     0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 32)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 64)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_mixed (Concatenate)   (None, 7, 7, 128)    0           activation_24[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_conv (Conv2D)         (None, 7, 7, 320)    41280       block35_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_3 (Lambda)              (None, 7, 7, 320)    0           block35_2_ac[0][0]               \n",
            "                                                                 block35_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_ac (Activation)       (None, 7, 7, 320)    0           block35_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 32)     10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 32)     96          conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 32)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 32)     10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 48)     13824       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 32)     96          conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 48)     144         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 32)     0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 48)     0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 32)     10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 32)     9216        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 64)     27648       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 32)     96          conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 32)     96          conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 64)     192         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 32)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 32)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 64)     0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_mixed (Concatenate)   (None, 7, 7, 128)    0           activation_30[0][0]              \n",
            "                                                                 activation_32[0][0]              \n",
            "                                                                 activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_conv (Conv2D)         (None, 7, 7, 320)    41280       block35_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_4 (Lambda)              (None, 7, 7, 320)    0           block35_3_ac[0][0]               \n",
            "                                                                 block35_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_ac (Activation)       (None, 7, 7, 320)    0           block35_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 32)     10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 32)     96          conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 32)     0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 32)     10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 48)     13824       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 32)     96          conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 48)     144         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 32)     0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 48)     0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 32)     10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 32)     9216        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 64)     27648       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 32)     96          conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 32)     96          conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 64)     192         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 32)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 32)     0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 64)     0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_mixed (Concatenate)   (None, 7, 7, 128)    0           activation_36[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_conv (Conv2D)         (None, 7, 7, 320)    41280       block35_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_5 (Lambda)              (None, 7, 7, 320)    0           block35_4_ac[0][0]               \n",
            "                                                                 block35_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_ac (Activation)       (None, 7, 7, 320)    0           block35_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 32)     10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 32)     96          conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 32)     0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 32)     10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 48)     13824       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 32)     96          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 48)     144         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 32)     0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 48)     0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 32)     10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 32)     9216        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 64)     27648       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 32)     96          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 32)     96          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 64)     192         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 32)     0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 32)     0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 64)     0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_mixed (Concatenate)   (None, 7, 7, 128)    0           activation_42[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_conv (Conv2D)         (None, 7, 7, 320)    41280       block35_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_6 (Lambda)              (None, 7, 7, 320)    0           block35_5_ac[0][0]               \n",
            "                                                                 block35_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_ac (Activation)       (None, 7, 7, 320)    0           block35_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 32)     10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 32)     96          conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 32)     0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 32)     10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 48)     13824       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 32)     96          conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 48)     144         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 32)     0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 48)     0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 32)     10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 32)     9216        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 64)     27648       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 32)     96          conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 32)     96          conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 64)     192         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 32)     0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 32)     0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 64)     0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_mixed (Concatenate)   (None, 7, 7, 128)    0           activation_48[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_conv (Conv2D)         (None, 7, 7, 320)    41280       block35_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_7 (Lambda)              (None, 7, 7, 320)    0           block35_6_ac[0][0]               \n",
            "                                                                 block35_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_ac (Activation)       (None, 7, 7, 320)    0           block35_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 32)     10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 32)     96          conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 32)     0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 32)     10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 48)     13824       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 32)     96          conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 48)     144         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 32)     0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 48)     0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 32)     10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 32)     9216        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 64)     27648       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 32)     96          conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 32)     96          conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 64)     192         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 32)     0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 32)     0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 64)     0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_mixed (Concatenate)   (None, 7, 7, 128)    0           activation_54[0][0]              \n",
            "                                                                 activation_56[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_conv (Conv2D)         (None, 7, 7, 320)    41280       block35_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_8 (Lambda)              (None, 7, 7, 320)    0           block35_7_ac[0][0]               \n",
            "                                                                 block35_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_ac (Activation)       (None, 7, 7, 320)    0           block35_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 32)     10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 32)     96          conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 32)     0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 32)     10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 48)     13824       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 32)     96          conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 48)     144         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 32)     0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 48)     0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 32)     10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 32)     9216        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 64)     27648       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 32)     96          conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 32)     96          conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 64)     192         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 32)     0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 32)     0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 64)     0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_mixed (Concatenate)   (None, 7, 7, 128)    0           activation_60[0][0]              \n",
            "                                                                 activation_62[0][0]              \n",
            "                                                                 activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_conv (Conv2D)         (None, 7, 7, 320)    41280       block35_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_9 (Lambda)              (None, 7, 7, 320)    0           block35_8_ac[0][0]               \n",
            "                                                                 block35_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_ac (Activation)       (None, 7, 7, 320)    0           block35_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 32)     10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 32)     96          conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 32)     0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 32)     10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 48)     13824       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 32)     96          conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 48)     144         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 32)     0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 48)     0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 32)     10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 32)     9216        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 7, 7, 64)     27648       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 32)     96          conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 32)     96          conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 7, 7, 64)     192         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 32)     0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 32)     0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 7, 7, 64)     0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_mixed (Concatenate)  (None, 7, 7, 128)    0           activation_66[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_conv (Conv2D)        (None, 7, 7, 320)    41280       block35_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block35_10 (Lambda)             (None, 7, 7, 320)    0           block35_9_ac[0][0]               \n",
            "                                                                 block35_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_ac (Activation)      (None, 7, 7, 320)    0           block35_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 256)    81920       block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 256)    768         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 256)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 256)    589824      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 256)    768         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 256)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 3, 3, 384)    1105920     block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 384)    884736      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 3, 3, 384)    1152        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 384)    1152        conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 3, 3, 384)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 384)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 320)    0           block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_6a (Concatenate)          (None, 3, 3, 1088)   0           activation_72[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 128)    139264      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 128)    384         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 128)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 160)    143360      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 160)    480         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 160)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 192)    208896      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 192)    215040      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 192)    576         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 192)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_mixed (Concatenate)   (None, 3, 3, 384)    0           activation_76[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_conv (Conv2D)         (None, 3, 3, 1088)   418880      block17_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_1 (Lambda)              (None, 3, 3, 1088)   0           mixed_6a[0][0]                   \n",
            "                                                                 block17_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_ac (Activation)       (None, 3, 3, 1088)   0           block17_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 128)    139264      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 128)    384         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 128)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 160)    143360      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 160)    480         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 160)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 192)    208896      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 192)    215040      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 192)    576         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 192)    576         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 192)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 192)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_mixed (Concatenate)   (None, 3, 3, 384)    0           activation_80[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_conv (Conv2D)         (None, 3, 3, 1088)   418880      block17_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_2 (Lambda)              (None, 3, 3, 1088)   0           block17_1_ac[0][0]               \n",
            "                                                                 block17_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_ac (Activation)       (None, 3, 3, 1088)   0           block17_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 128)    139264      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 128)    384         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 128)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 160)    143360      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 160)    480         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 160)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    208896      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 192)    215040      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 192)    576         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 192)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_mixed (Concatenate)   (None, 3, 3, 384)    0           activation_84[0][0]              \n",
            "                                                                 activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_conv (Conv2D)         (None, 3, 3, 1088)   418880      block17_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_3 (Lambda)              (None, 3, 3, 1088)   0           block17_2_ac[0][0]               \n",
            "                                                                 block17_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_ac (Activation)       (None, 3, 3, 1088)   0           block17_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 128)    139264      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 128)    384         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 128)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 160)    143360      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 160)    480         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 160)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 192)    208896      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 192)    215040      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 192)    576         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 192)    576         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 192)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 192)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_mixed (Concatenate)   (None, 3, 3, 384)    0           activation_88[0][0]              \n",
            "                                                                 activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_conv (Conv2D)         (None, 3, 3, 1088)   418880      block17_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_4 (Lambda)              (None, 3, 3, 1088)   0           block17_3_ac[0][0]               \n",
            "                                                                 block17_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_ac (Activation)       (None, 3, 3, 1088)   0           block17_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 128)    139264      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 128)    384         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 128)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 3, 3, 160)    143360      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 3, 3, 160)    480         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 3, 3, 160)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 192)    208896      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 3, 3, 192)    215040      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 192)    576         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 3, 3, 192)    576         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 192)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 3, 3, 192)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_mixed (Concatenate)   (None, 3, 3, 384)    0           activation_92[0][0]              \n",
            "                                                                 activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_conv (Conv2D)         (None, 3, 3, 1088)   418880      block17_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_5 (Lambda)              (None, 3, 3, 1088)   0           block17_4_ac[0][0]               \n",
            "                                                                 block17_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_ac (Activation)       (None, 3, 3, 1088)   0           block17_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 3, 3, 128)    139264      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 3, 3, 128)    384         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 3, 3, 128)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 3, 3, 160)    143360      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 3, 3, 160)    480         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 3, 3, 160)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 3, 3, 192)    208896      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 3, 3, 192)    215040      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 3, 3, 192)    576         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 3, 3, 192)    576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 3, 3, 192)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 3, 3, 192)    0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_mixed (Concatenate)   (None, 3, 3, 384)    0           activation_96[0][0]              \n",
            "                                                                 activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_conv (Conv2D)         (None, 3, 3, 1088)   418880      block17_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_6 (Lambda)              (None, 3, 3, 1088)   0           block17_5_ac[0][0]               \n",
            "                                                                 block17_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_ac (Activation)       (None, 3, 3, 1088)   0           block17_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 3, 3, 128)    139264      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 3, 3, 128)    384         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 3, 3, 128)    0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 3, 3, 160)    143360      activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 3, 3, 160)    480         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 3, 3, 160)    0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 3, 3, 192)    208896      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 3, 3, 192)    215040      activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 3, 3, 192)    576         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 3, 3, 192)    576         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 3, 3, 192)    0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 3, 3, 192)    0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_mixed (Concatenate)   (None, 3, 3, 384)    0           activation_100[0][0]             \n",
            "                                                                 activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_conv (Conv2D)         (None, 3, 3, 1088)   418880      block17_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_7 (Lambda)              (None, 3, 3, 1088)   0           block17_6_ac[0][0]               \n",
            "                                                                 block17_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_ac (Activation)       (None, 3, 3, 1088)   0           block17_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 3, 3, 128)    139264      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 3, 3, 128)    384         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 3, 3, 128)    0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 3, 3, 160)    143360      activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 3, 3, 160)    480         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 3, 3, 160)    0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 3, 3, 192)    208896      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 3, 3, 192)    215040      activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 3, 3, 192)    576         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 3, 3, 192)    576         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 3, 3, 192)    0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 3, 3, 192)    0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_mixed (Concatenate)   (None, 3, 3, 384)    0           activation_104[0][0]             \n",
            "                                                                 activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_conv (Conv2D)         (None, 3, 3, 1088)   418880      block17_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_8 (Lambda)              (None, 3, 3, 1088)   0           block17_7_ac[0][0]               \n",
            "                                                                 block17_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_ac (Activation)       (None, 3, 3, 1088)   0           block17_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 3, 3, 128)    139264      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 3, 3, 128)    384         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 3, 3, 128)    0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 3, 3, 160)    143360      activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 3, 3, 160)    480         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 3, 3, 160)    0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 3, 3, 192)    208896      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 3, 3, 192)    215040      activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 3, 3, 192)    576         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 3, 3, 192)    576         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 3, 3, 192)    0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 3, 3, 192)    0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_mixed (Concatenate)   (None, 3, 3, 384)    0           activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_conv (Conv2D)         (None, 3, 3, 1088)   418880      block17_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_9 (Lambda)              (None, 3, 3, 1088)   0           block17_8_ac[0][0]               \n",
            "                                                                 block17_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_ac (Activation)       (None, 3, 3, 1088)   0           block17_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 3, 3, 128)    139264      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 3, 3, 128)    384         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 3, 3, 128)    0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 3, 3, 160)    143360      activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 3, 3, 160)    480         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 3, 3, 160)    0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 3, 3, 192)    208896      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 3, 3, 192)    215040      activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 3, 3, 192)    576         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 3, 3, 192)    576         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 3, 3, 192)    0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 3, 3, 192)    0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_mixed (Concatenate)  (None, 3, 3, 384)    0           activation_112[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_conv (Conv2D)        (None, 3, 3, 1088)   418880      block17_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_10 (Lambda)             (None, 3, 3, 1088)   0           block17_9_ac[0][0]               \n",
            "                                                                 block17_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_ac (Activation)      (None, 3, 3, 1088)   0           block17_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 3, 3, 128)    139264      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 3, 3, 128)    384         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 3, 3, 128)    0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 3, 3, 160)    143360      activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 3, 3, 160)    480         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 3, 3, 160)    0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 3, 3, 192)    208896      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 3, 3, 192)    215040      activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 3, 3, 192)    576         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 3, 3, 192)    576         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 3, 3, 192)    0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 3, 3, 192)    0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_mixed (Concatenate)  (None, 3, 3, 384)    0           activation_116[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_conv (Conv2D)        (None, 3, 3, 1088)   418880      block17_11_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_11 (Lambda)             (None, 3, 3, 1088)   0           block17_10_ac[0][0]              \n",
            "                                                                 block17_11_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_ac (Activation)      (None, 3, 3, 1088)   0           block17_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 3, 3, 128)    139264      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 3, 3, 128)    384         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 3, 3, 128)    0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 3, 3, 160)    143360      activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 3, 3, 160)    480         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 3, 3, 160)    0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 3, 3, 192)    208896      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 3, 3, 192)    215040      activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 3, 3, 192)    576         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 3, 3, 192)    576         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 3, 3, 192)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 3, 3, 192)    0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_mixed (Concatenate)  (None, 3, 3, 384)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_conv (Conv2D)        (None, 3, 3, 1088)   418880      block17_12_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_12 (Lambda)             (None, 3, 3, 1088)   0           block17_11_ac[0][0]              \n",
            "                                                                 block17_12_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_ac (Activation)      (None, 3, 3, 1088)   0           block17_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 3, 3, 128)    139264      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 3, 3, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 3, 3, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 3, 3, 160)    143360      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 3, 3, 160)    480         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 3, 3, 160)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 3, 3, 192)    208896      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 3, 3, 192)    215040      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 3, 3, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 3, 3, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 3, 3, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 3, 3, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_mixed (Concatenate)  (None, 3, 3, 384)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_conv (Conv2D)        (None, 3, 3, 1088)   418880      block17_13_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_13 (Lambda)             (None, 3, 3, 1088)   0           block17_12_ac[0][0]              \n",
            "                                                                 block17_13_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_ac (Activation)      (None, 3, 3, 1088)   0           block17_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 3, 3, 128)    139264      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 3, 3, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 3, 3, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 3, 3, 160)    143360      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 3, 3, 160)    480         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 3, 3, 160)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 3, 3, 192)    208896      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 3, 3, 192)    215040      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 3, 3, 192)    576         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 3, 3, 192)    576         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 3, 3, 192)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 3, 3, 192)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_mixed (Concatenate)  (None, 3, 3, 384)    0           activation_128[0][0]             \n",
            "                                                                 activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_conv (Conv2D)        (None, 3, 3, 1088)   418880      block17_14_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_14 (Lambda)             (None, 3, 3, 1088)   0           block17_13_ac[0][0]              \n",
            "                                                                 block17_14_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_ac (Activation)      (None, 3, 3, 1088)   0           block17_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 3, 3, 128)    139264      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 3, 3, 128)    384         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 3, 3, 128)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 3, 3, 160)    143360      activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 3, 3, 160)    480         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 3, 3, 160)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 3, 3, 192)    208896      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 3, 3, 192)    215040      activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 3, 3, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 3, 3, 192)    576         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 3, 3, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 3, 3, 192)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_mixed (Concatenate)  (None, 3, 3, 384)    0           activation_132[0][0]             \n",
            "                                                                 activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_conv (Conv2D)        (None, 3, 3, 1088)   418880      block17_15_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_15 (Lambda)             (None, 3, 3, 1088)   0           block17_14_ac[0][0]              \n",
            "                                                                 block17_15_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_ac (Activation)      (None, 3, 3, 1088)   0           block17_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 3, 3, 128)    139264      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 3, 3, 128)    384         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 3, 3, 128)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 3, 3, 160)    143360      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 3, 3, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 3, 3, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 3, 3, 192)    208896      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 3, 3, 192)    215040      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 3, 3, 192)    576         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 3, 3, 192)    576         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 3, 3, 192)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 3, 3, 192)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_mixed (Concatenate)  (None, 3, 3, 384)    0           activation_136[0][0]             \n",
            "                                                                 activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_conv (Conv2D)        (None, 3, 3, 1088)   418880      block17_16_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_16 (Lambda)             (None, 3, 3, 1088)   0           block17_15_ac[0][0]              \n",
            "                                                                 block17_16_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_ac (Activation)      (None, 3, 3, 1088)   0           block17_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 3, 3, 128)    139264      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 3, 3, 128)    384         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 3, 3, 128)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 3, 3, 160)    143360      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 3, 3, 160)    480         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 3, 3, 160)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 3, 3, 192)    208896      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 3, 3, 192)    215040      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 3, 3, 192)    576         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 3, 3, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 3, 3, 192)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 3, 3, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_mixed (Concatenate)  (None, 3, 3, 384)    0           activation_140[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_conv (Conv2D)        (None, 3, 3, 1088)   418880      block17_17_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_17 (Lambda)             (None, 3, 3, 1088)   0           block17_16_ac[0][0]              \n",
            "                                                                 block17_17_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_ac (Activation)      (None, 3, 3, 1088)   0           block17_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 3, 3, 128)    139264      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 3, 3, 128)    384         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 3, 3, 128)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 3, 3, 160)    143360      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 3, 3, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 3, 3, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 3, 3, 192)    208896      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 3, 3, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 3, 3, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 3, 3, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 3, 3, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 3, 3, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_mixed (Concatenate)  (None, 3, 3, 384)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_conv (Conv2D)        (None, 3, 3, 1088)   418880      block17_18_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_18 (Lambda)             (None, 3, 3, 1088)   0           block17_17_ac[0][0]              \n",
            "                                                                 block17_18_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_ac (Activation)      (None, 3, 3, 1088)   0           block17_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 3, 3, 128)    139264      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 3, 3, 128)    384         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 3, 3, 128)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 3, 3, 160)    143360      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 3, 3, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 3, 3, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 3, 3, 192)    208896      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 3, 3, 192)    215040      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 3, 3, 192)    576         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 3, 3, 192)    576         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 3, 3, 192)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 3, 3, 192)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_mixed (Concatenate)  (None, 3, 3, 384)    0           activation_148[0][0]             \n",
            "                                                                 activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_conv (Conv2D)        (None, 3, 3, 1088)   418880      block17_19_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_19 (Lambda)             (None, 3, 3, 1088)   0           block17_18_ac[0][0]              \n",
            "                                                                 block17_19_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_ac (Activation)      (None, 3, 3, 1088)   0           block17_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 3, 3, 128)    139264      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 3, 3, 128)    384         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 3, 3, 128)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 3, 3, 160)    143360      activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 3, 3, 160)    480         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 3, 3, 160)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 3, 3, 192)    208896      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 3, 3, 192)    215040      activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 3, 3, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 3, 3, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 3, 3, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 3, 3, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_mixed (Concatenate)  (None, 3, 3, 384)    0           activation_152[0][0]             \n",
            "                                                                 activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_conv (Conv2D)        (None, 3, 3, 1088)   418880      block17_20_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_20 (Lambda)             (None, 3, 3, 1088)   0           block17_19_ac[0][0]              \n",
            "                                                                 block17_20_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_ac (Activation)      (None, 3, 3, 1088)   0           block17_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 3, 3, 256)    278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 3, 3, 256)    768         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 3, 3, 256)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 3, 3, 256)    278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 3, 3, 256)    278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 3, 3, 288)    663552      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 3, 3, 256)    768         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 3, 3, 256)    768         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 3, 3, 288)    864         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 3, 3, 256)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 3, 3, 256)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 3, 3, 288)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 1, 1, 384)    884736      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 1, 1, 288)    663552      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 1, 1, 320)    829440      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 1, 1, 384)    1152        conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 1, 1, 288)    864         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 1, 1, 320)    960         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 1, 1, 384)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 1, 1, 288)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 1, 1, 320)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 1088)   0           block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_7a (Concatenate)          (None, 1, 1, 2080)   0           activation_157[0][0]             \n",
            "                                                                 activation_159[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 1, 1, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 1, 1, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 1, 1, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 1, 1, 224)    129024      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 1, 1, 224)    672         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 1, 1, 224)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 1, 1, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 1, 1, 256)    172032      activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 1, 1, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 1, 1, 256)    768         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 1, 1, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 1, 1, 256)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_mixed (Concatenate)    (None, 1, 1, 448)    0           activation_163[0][0]             \n",
            "                                                                 activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_conv (Conv2D)          (None, 1, 1, 2080)   933920      block8_1_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1 (Lambda)               (None, 1, 1, 2080)   0           mixed_7a[0][0]                   \n",
            "                                                                 block8_1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_ac (Activation)        (None, 1, 1, 2080)   0           block8_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 1, 1, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 1, 1, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 1, 1, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 1, 1, 224)    129024      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 1, 1, 224)    672         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 1, 1, 224)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 1, 1, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 1, 1, 256)    172032      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 1, 1, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 1, 1, 256)    768         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 1, 1, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 1, 1, 256)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_mixed (Concatenate)    (None, 1, 1, 448)    0           activation_167[0][0]             \n",
            "                                                                 activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_conv (Conv2D)          (None, 1, 1, 2080)   933920      block8_2_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2 (Lambda)               (None, 1, 1, 2080)   0           block8_1_ac[0][0]                \n",
            "                                                                 block8_2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_ac (Activation)        (None, 1, 1, 2080)   0           block8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 1, 1, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 1, 1, 192)    576         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 1, 1, 192)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 1, 1, 224)    129024      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 1, 1, 224)    672         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 1, 1, 224)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 1, 1, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 1, 1, 256)    172032      activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 1, 1, 192)    576         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 1, 1, 256)    768         conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 1, 1, 192)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 1, 1, 256)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_mixed (Concatenate)    (None, 1, 1, 448)    0           activation_171[0][0]             \n",
            "                                                                 activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_conv (Conv2D)          (None, 1, 1, 2080)   933920      block8_3_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3 (Lambda)               (None, 1, 1, 2080)   0           block8_2_ac[0][0]                \n",
            "                                                                 block8_3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_ac (Activation)        (None, 1, 1, 2080)   0           block8_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 1, 1, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 1, 1, 192)    576         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 1, 1, 192)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 1, 1, 224)    129024      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 1, 1, 224)    672         conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 1, 1, 224)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 1, 1, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 1, 1, 256)    172032      activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 1, 1, 192)    576         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 1, 1, 256)    768         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 1, 1, 192)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 1, 1, 256)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_mixed (Concatenate)    (None, 1, 1, 448)    0           activation_175[0][0]             \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_conv (Conv2D)          (None, 1, 1, 2080)   933920      block8_4_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4 (Lambda)               (None, 1, 1, 2080)   0           block8_3_ac[0][0]                \n",
            "                                                                 block8_4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_ac (Activation)        (None, 1, 1, 2080)   0           block8_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 1, 1, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 1, 1, 192)    576         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 1, 1, 192)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 1, 1, 224)    129024      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 1, 1, 224)    672         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 1, 1, 224)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 1, 1, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 1, 1, 256)    172032      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 1, 1, 192)    576         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 1, 1, 256)    768         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 1, 1, 192)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 1, 1, 256)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_mixed (Concatenate)    (None, 1, 1, 448)    0           activation_179[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_conv (Conv2D)          (None, 1, 1, 2080)   933920      block8_5_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5 (Lambda)               (None, 1, 1, 2080)   0           block8_4_ac[0][0]                \n",
            "                                                                 block8_5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_ac (Activation)        (None, 1, 1, 2080)   0           block8_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 1, 1, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 1, 1, 192)    576         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 1, 1, 192)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 1, 1, 224)    129024      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 1, 1, 224)    672         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 1, 1, 224)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 1, 1, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 1, 1, 256)    172032      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 1, 1, 192)    576         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 1, 1, 256)    768         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 1, 1, 192)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 1, 1, 256)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_mixed (Concatenate)    (None, 1, 1, 448)    0           activation_183[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_conv (Conv2D)          (None, 1, 1, 2080)   933920      block8_6_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6 (Lambda)               (None, 1, 1, 2080)   0           block8_5_ac[0][0]                \n",
            "                                                                 block8_6_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_ac (Activation)        (None, 1, 1, 2080)   0           block8_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 1, 1, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 1, 1, 192)    576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 1, 1, 192)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 1, 1, 224)    129024      activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 1, 1, 224)    672         conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 1, 1, 224)    0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 1, 1, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 1, 1, 256)    172032      activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 1, 1, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 1, 1, 256)    768         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 1, 1, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 1, 1, 256)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_mixed (Concatenate)    (None, 1, 1, 448)    0           activation_187[0][0]             \n",
            "                                                                 activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_conv (Conv2D)          (None, 1, 1, 2080)   933920      block8_7_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7 (Lambda)               (None, 1, 1, 2080)   0           block8_6_ac[0][0]                \n",
            "                                                                 block8_7_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_ac (Activation)        (None, 1, 1, 2080)   0           block8_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 1, 1, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 1, 1, 192)    576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 1, 1, 192)    0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 1, 1, 224)    129024      activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 1, 1, 224)    672         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 1, 1, 224)    0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 1, 1, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 1, 1, 256)    172032      activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 1, 1, 192)    576         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 1, 1, 256)    768         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 1, 1, 192)    0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 1, 1, 256)    0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_mixed (Concatenate)    (None, 1, 1, 448)    0           activation_191[0][0]             \n",
            "                                                                 activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_conv (Conv2D)          (None, 1, 1, 2080)   933920      block8_8_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8 (Lambda)               (None, 1, 1, 2080)   0           block8_7_ac[0][0]                \n",
            "                                                                 block8_8_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_ac (Activation)        (None, 1, 1, 2080)   0           block8_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 1, 1, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 1, 1, 192)    576         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 1, 1, 192)    0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 1, 1, 224)    129024      activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 1, 1, 224)    672         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 1, 1, 224)    0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 1, 1, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 1, 1, 256)    172032      activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 1, 1, 192)    576         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 1, 1, 256)    768         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 1, 1, 192)    0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 1, 1, 256)    0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_mixed (Concatenate)    (None, 1, 1, 448)    0           activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_conv (Conv2D)          (None, 1, 1, 2080)   933920      block8_9_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9 (Lambda)               (None, 1, 1, 2080)   0           block8_8_ac[0][0]                \n",
            "                                                                 block8_9_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_ac (Activation)        (None, 1, 1, 2080)   0           block8_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 1, 1, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 1, 1, 192)    576         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 1, 1, 192)    0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 1, 1, 224)    129024      activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 1, 1, 224)    672         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 1, 1, 224)    0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 1, 1, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 1, 1, 256)    172032      activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 1, 1, 192)    576         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 1, 1, 256)    768         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 1, 1, 192)    0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 1, 1, 256)    0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_mixed (Concatenate)   (None, 1, 1, 448)    0           activation_199[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_conv (Conv2D)         (None, 1, 1, 2080)   933920      block8_10_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10 (Lambda)              (None, 1, 1, 2080)   0           block8_9_ac[0][0]                \n",
            "                                                                 block8_10_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b (Conv2D)                (None, 1, 1, 1536)   3194880     block8_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_bn (BatchNormalization) (None, 1, 1, 1536)   4608        conv_7b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_ac (Activation)         (None, 1, 1, 1536)   0           conv_7b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1536)         0           conv_7b_ac[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1536)         0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 27)           41499       dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 54,378,235\n",
            "Trainable params: 54,317,691\n",
            "Non-trainable params: 60,544\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4dY7e3zwp46",
        "colab_type": "text"
      },
      "source": [
        "#### Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyBTl-6XpBFF",
        "colab_type": "code",
        "outputId": "ace0802e-8a3b-45dd-8575-1a3f3e56047b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test),shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2964/2964 [==============================] - 365s 123ms/step - loss: 0.3505 - acc: 0.9038 - mse: 0.0054 - val_loss: 0.8057 - val_acc: 0.8481 - val_mse: 0.0092\n",
            "Epoch 2/10\n",
            "2964/2964 [==============================] - 362s 122ms/step - loss: 0.1887 - acc: 0.9493 - mse: 0.0029 - val_loss: 0.3004 - val_acc: 0.9283 - val_mse: 0.0041\n",
            "Epoch 3/10\n",
            "2964/2964 [==============================] - 362s 122ms/step - loss: 0.1473 - acc: 0.9600 - mse: 0.0023 - val_loss: 0.2514 - val_acc: 0.9435 - val_mse: 0.0033\n",
            "Epoch 4/10\n",
            "2964/2964 [==============================] - 361s 122ms/step - loss: 0.1236 - acc: 0.9671 - mse: 0.0019 - val_loss: 0.3143 - val_acc: 0.9328 - val_mse: 0.0039\n",
            "Epoch 5/10\n",
            "2964/2964 [==============================] - 361s 122ms/step - loss: 0.1025 - acc: 0.9724 - mse: 0.0016 - val_loss: 0.2146 - val_acc: 0.9540 - val_mse: 0.0028\n",
            "Epoch 6/10\n",
            "2964/2964 [==============================] - 362s 122ms/step - loss: 0.0934 - acc: 0.9759 - mse: 0.0014 - val_loss: 0.2089 - val_acc: 0.9513 - val_mse: 0.0029\n",
            "Epoch 7/10\n",
            "2964/2964 [==============================] - 362s 122ms/step - loss: 0.0690 - acc: 0.9810 - mse: 0.0011 - val_loss: 0.2381 - val_acc: 0.9474 - val_mse: 0.0031\n",
            "Epoch 8/10\n",
            "2964/2964 [==============================] - 365s 123ms/step - loss: 0.0711 - acc: 0.9810 - mse: 0.0011 - val_loss: 0.2596 - val_acc: 0.9472 - val_mse: 0.0031\n",
            "Epoch 9/10\n",
            "2964/2964 [==============================] - 364s 123ms/step - loss: 0.0596 - acc: 0.9837 - mse: 9.4874e-04 - val_loss: 0.2982 - val_acc: 0.9466 - val_mse: 0.0033\n",
            "Epoch 10/10\n",
            "2964/2964 [==============================] - 362s 122ms/step - loss: 0.0514 - acc: 0.9856 - mse: 8.4357e-04 - val_loss: 0.2286 - val_acc: 0.9523 - val_mse: 0.0028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxvGfr1nLcvA",
        "colab_type": "code",
        "outputId": "6375520e-5625-49b2-ab64-c03a0833495d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "accuracy = history.history['acc']\n",
        "val_accuracy = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJs5ZojfGmDj3/6oo+Lr3D5XOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMWCa8Glfihx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/gdrive/My Drive/Colab Notebooks/model_letters_space_xx.h5')\n",
        "model.save_weights('/content/gdrive/My Drive/Colab Notebooks/model_weights_letters_space_xx.h5')\n",
        "#model.load_weights('my_model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrvjpsv5P7aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import sklearn.metrics as metrics\n",
        "\n",
        "# y_pred_ohe = KerasClassifier.predict(X)  # shape=(n_samples, 12)\n",
        "# y_pred_labels = np.argmax(y_pred_ohe, axis=1)  # only necessary if output has one-hot-encoding, shape=(n_samples)\n",
        "\n",
        "# confusion_matrix = metrics.confusion_matrix(y_true=y_true_labels, y_pred=y_pred_labels)  # shape=(12, 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odcpA7kHQQRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# y_pred = model.predict(x_test, batch_size=64, verbose=1)\n",
        "# y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# print(classification_report(y_test, y_pred_bool))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnYl-KSuUGxN",
        "colab_type": "code",
        "outputId": "222ef261-61bb-4223-b301-85a5513ceeca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "d# Inception model\n",
        "\n",
        "from keras.layers import Input\n",
        "input_img = Input(shape = (32, 32, 3))\n",
        "\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "tower_1 = Conv2D(128, (1,1), padding='same', activation='relu')(input_img)\n",
        "tower_1 = Conv2D(128, (3,3), padding='same', activation='relu')(tower_1)\n",
        "tower_1= Dropout(0.3)(tower_1)\n",
        "tower_2 = Conv2D(128, (1,1), padding='same', activation='relu')(input_img)\n",
        "tower_2 = Conv2D(128, (5,5), padding='same', activation='relu')(tower_2)\n",
        "tower_2= Dropout(0.3)(tower_2)\n",
        "tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
        "tower_3 = Conv2D(128, (1,1), padding='same', activation='relu')(tower_3)\n",
        "\n",
        "\n",
        "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis = 3)\n",
        "\n",
        "\n",
        "from keras.layers import Flatten, Dense\n",
        "output = Flatten()(output)\n",
        "out    = Dense(10, activation='softmax')(output)\n",
        "\n",
        "from keras.models import Model\n",
        "model = Model(inputs = input_img, outputs = out)\n",
        "print (model.summary())\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 32, 32, 128)  512         input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 32, 32, 128)  512         input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 32, 32, 128)  147584      conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 32, 32, 128)  409728      conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling2D) (None, 32, 32, 3)    0           input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 32, 32, 128)  0           conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 32, 32, 128)  0           conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 32, 32, 128)  512         max_pooling2d_30[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 32, 32, 384)  0           dropout_21[0][0]                 \n",
            "                                                                 dropout_22[0][0]                 \n",
            "                                                                 conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 393216)       0           concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 10)           3932170     flatten_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 4,491,018\n",
            "Trainable params: 4,491,018\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0TecwRut9Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a mlp model\n",
        "from keras.layers import Dense, Activation\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Dense(1000, activation='relu',kernel_initializer='uniform',input_shape=(32, 32,3)))\n",
        "keras.layers.core.Dropout(0.3, noise_shape=None, seed=None)\n",
        "\n",
        "model.add(Dense(500,activation='sigmoid'))\n",
        "keras.layers.core.Dropout(0.4, noise_shape=None, seed=None)\n",
        "\n",
        "model.add(Dense(150,activation='sigmoid'))\n",
        "keras.layers.core.Dropout(0.2, noise_shape=None, seed=None)\n",
        "\n",
        "model.add(Dense(units=10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtnQKZ6QuqgI",
        "colab_type": "code",
        "outputId": "4eda0db6-a939-4fb1-8df2-912a43304163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 32, 32, 1000)      4000      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 32, 32, 500)       500500    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 32, 32, 150)       75150     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 32, 32, 10)        1510      \n",
            "_________________________________________________________________\n",
            "activation_612 (Activation)  (None, 32, 32, 10)        0         \n",
            "=================================================================\n",
            "Total params: 581,160\n",
            "Trainable params: 581,160\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCoKbIjoUG0q",
        "colab_type": "code",
        "outputId": "94821dc7-cf60-4bcf-eb01-038cf093bc22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test),shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24711 samples, validate on 2295 samples\n",
            "Epoch 1/5\n",
            "24711/24711 [==============================] - 211s 9ms/step - loss: 0.0114 - acc: 0.9969 - mean_squared_error: 4.8363e-04 - val_loss: 0.2531 - val_acc: 0.9490 - val_mean_squared_error: 0.0084\n",
            "Epoch 2/5\n",
            "24711/24711 [==============================] - 210s 9ms/step - loss: 0.0167 - acc: 0.9960 - mean_squared_error: 6.4538e-04 - val_loss: 0.1909 - val_acc: 0.9569 - val_mean_squared_error: 0.0070\n",
            "Epoch 3/5\n",
            "24711/24711 [==============================] - 210s 9ms/step - loss: 0.0411 - acc: 0.9920 - mean_squared_error: 0.0014 - val_loss: 0.1158 - val_acc: 0.9795 - val_mean_squared_error: 0.0036\n",
            "Epoch 4/5\n",
            "24711/24711 [==============================] - 210s 8ms/step - loss: 0.0130 - acc: 0.9969 - mean_squared_error: 5.2588e-04 - val_loss: 0.1086 - val_acc: 0.9760 - val_mean_squared_error: 0.0037\n",
            "Epoch 5/5\n",
            "24711/24711 [==============================] - 210s 9ms/step - loss: 0.0071 - acc: 0.9979 - mean_squared_error: 3.2507e-04 - val_loss: 0.1315 - val_acc: 0.9686 - val_mean_squared_error: 0.0047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObXM-1xdwOmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " model.save('/content/gdrive/My Drive/Colab Notebooks/model_digits_97.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFkBG7peUwQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # We have grayscale images, so while loading the images we will keep grayscale=True, if you have RGB images, you should set grayscale as False\n",
        "# from tqdm import tqdm\n",
        "# from keras.utils import to_categorical\n",
        "# from keras.preprocessing import image\n",
        "# test_image = []\n",
        "# for i in tqdm(range(test.shape[0])):\n",
        "#     im_buf = test.values[i][0:]\n",
        "#     im_array = np.int8(np.reshape(im_buf, (32, 32))) \n",
        "#     #img = image.load_img(train.iloc[:,1:].as_matrix().astype('str'), target_size=(64,64,1), color_mode='grayscale')\n",
        "#     img = image.img_to_array(im_array)\n",
        "#     img = img/255\n",
        "#     test_image.append(img)\n",
        "# X_test = np.array(test_image)\n",
        "# X_test = np.repeat(X_test, 3, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXFJTAH4UwMK",
        "colab_type": "code",
        "outputId": "3a69ebaf-2728-43bb-9b81-3cb7f60d6a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "model = load_model(\"/content/gdrive/My Drive/Colab Notebooks/model_all chars_89.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-25b1c30d1e45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/Colab Notebooks/model_all chars_89.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    591\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 147\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 1029\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   1030\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    147\u001b[0m                                         list(custom_objects.items())))\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[1;32m     85\u001b[0m                                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                                          \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                                          name=self.name)\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(shape, ndim, dtype, sparse, name)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_placeholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ql6cldYUv1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pred=model.predict(X_test)\n",
        "# for i in pred:\n",
        "#   print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oJF4rBhZJhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.argmax(pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVTlIFN9-hdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\t\n",
        "# example of creating a CNN with an efficient inception module\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.utils import plot_model\n",
        " \n",
        "# function for creating a projected inception module\n",
        "def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
        "\t# 1x1 conv\n",
        "\tconv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\t# 3x3 conv\n",
        "\tconv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\tconv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
        "\t# 5x5 conv\n",
        "\tconv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\tconv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
        "\t# 3x3 max pooling\n",
        "\tpool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
        "\tpool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
        "\t# concatenate filters, assumes filters/channels last\n",
        "\tlayer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
        "\treturn layer_out\n",
        " \n",
        "# define model input\n",
        "visible = Input(shape=(32, 32, 3))\n",
        "# add inception block 1\n",
        "layer = inception_module(visible, 96, 96, 64, 64, 32, 32)\n",
        "layer=Dropout(0.5)(layer)\n",
        "# add inception block 1\n",
        "# layer = inception_module(layer, 64, 64, 64, 64, 32, 32)\n",
        "# layer=Dropout(0.5)(layer)\n",
        "layer = inception_module(layer, 64, 64, 32, 32, 40, 40)\n",
        "\n",
        "# create model\n",
        "\n",
        "from keras.layers import Flatten, Dense\n",
        "output = Flatten()(layer)\n",
        "out    = Dense(10, activation='softmax')(output)\n",
        "# model = Model(inputs = input_img, outputs = out)\n",
        "model = Model(inputs=visible, outputs=out)\n",
        "\n",
        "\n",
        "# summarize model\n",
        "#model.summary()\n",
        "# plot model architecture\n",
        "#plot_model(model, show_shapes=True, to_file='inception_module.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obl0DfYsAVh9",
        "colab_type": "code",
        "outputId": "abdf470b-b2a3-4225-bda8-9125542d607d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test),shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-3df4610e8247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_3_input to have 2 dimensions, but got array with shape (30000, 32, 32, 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR09fFmtYY8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " model.save('/content/gdrive/My Drive/Colab Notebooks/model_digits_trial_85.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikd2vXSjUG5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# old_model = load_model('/content/drive/My Drive/colab/my_letters16.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_lUz5vqUGzm",
        "colab_type": "code",
        "outputId": "5fe47be3-3b7f-44a3-82cd-23225a292863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.utils import plot_model\n",
        "cnn1 = Sequential()\n",
        "cnn1.add(Conv2D(1024, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)))\n",
        "cnn1.add(Dropout(0.4))\n",
        "cnn1.add(Conv2D(128, kernel_size=(1, 1), activation='relu'))\n",
        "# cnn1.add(Dropout(0.4))\n",
        "#cnn1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# cnn1.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)))\n",
        "# cnn1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# cnn1.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "# cnn1.add(Dropout(0.6))\n",
        "cnn1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn1.add(Flatten())\n",
        "cnn1.add(Dense(10, activation='softmax'))\n",
        "#cnn1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3fbd9d90f635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcnn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_subclassed_network\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_base_init\u001b[0;34m(self, name, trainable, dtype)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;34m'It looks like you are trying to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;34m'a version of multi-backend Keras that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;34m'does not support TensorFlow 2.0. We recommend '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQPQAqAVUGqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn1.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxETr6ydFWZH",
        "colab_type": "code",
        "outputId": "17d6d8e1-247e-49a1-9e70-09478f53f75c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = cnn1.fit(X_train, y_train, epochs=75, validation_data=(X_test, y_test),shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 2295 samples\n",
            "Epoch 1/75\n",
            "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6735 - acc: 0.7165 - val_loss: 8.9809 - val_acc: 0.2205\n",
            "Epoch 2/75\n",
            "10000/10000 [==============================] - 7s 691us/step - loss: 0.2295 - acc: 0.9226 - val_loss: 9.3981 - val_acc: 0.2209\n",
            "Epoch 3/75\n",
            "10000/10000 [==============================] - 7s 690us/step - loss: 0.1814 - acc: 0.9373 - val_loss: 9.4056 - val_acc: 0.2279\n",
            "Epoch 4/75\n",
            "10000/10000 [==============================] - 7s 693us/step - loss: 0.1337 - acc: 0.9546 - val_loss: 9.1252 - val_acc: 0.2545\n",
            "Epoch 5/75\n",
            "10000/10000 [==============================] - 7s 698us/step - loss: 0.0934 - acc: 0.9691 - val_loss: 9.7815 - val_acc: 0.2475\n",
            "Epoch 6/75\n",
            "10000/10000 [==============================] - 7s 687us/step - loss: 0.0723 - acc: 0.9753 - val_loss: 9.6621 - val_acc: 0.2728\n",
            "Epoch 7/75\n",
            "10000/10000 [==============================] - 7s 692us/step - loss: 0.0613 - acc: 0.9797 - val_loss: 9.8648 - val_acc: 0.2710\n",
            "Epoch 8/75\n",
            "10000/10000 [==============================] - 7s 690us/step - loss: 0.0493 - acc: 0.9842 - val_loss: 9.7117 - val_acc: 0.2771\n",
            "Epoch 9/75\n",
            "10000/10000 [==============================] - 7s 692us/step - loss: 0.0466 - acc: 0.9844 - val_loss: 9.5529 - val_acc: 0.2845\n",
            "Epoch 10/75\n",
            "10000/10000 [==============================] - 7s 692us/step - loss: 0.0463 - acc: 0.9846 - val_loss: 9.2666 - val_acc: 0.2845\n",
            "Epoch 11/75\n",
            "10000/10000 [==============================] - 7s 694us/step - loss: 0.0327 - acc: 0.9890 - val_loss: 10.1413 - val_acc: 0.2732\n",
            "Epoch 12/75\n",
            "10000/10000 [==============================] - 7s 696us/step - loss: 0.0311 - acc: 0.9882 - val_loss: 9.7954 - val_acc: 0.2815\n",
            "Epoch 13/75\n",
            "10000/10000 [==============================] - 7s 691us/step - loss: 0.0341 - acc: 0.9870 - val_loss: 9.7933 - val_acc: 0.2889\n",
            "Epoch 14/75\n",
            "10000/10000 [==============================] - 7s 696us/step - loss: 0.0295 - acc: 0.9883 - val_loss: 9.4739 - val_acc: 0.2932\n",
            "Epoch 15/75\n",
            "10000/10000 [==============================] - 7s 691us/step - loss: 0.0269 - acc: 0.9906 - val_loss: 9.6368 - val_acc: 0.2980\n",
            "Epoch 16/75\n",
            "10000/10000 [==============================] - 7s 689us/step - loss: 0.0243 - acc: 0.9919 - val_loss: 9.8027 - val_acc: 0.2928\n",
            "Epoch 17/75\n",
            "10000/10000 [==============================] - 7s 692us/step - loss: 0.0256 - acc: 0.9907 - val_loss: 9.7055 - val_acc: 0.2980\n",
            "Epoch 18/75\n",
            "10000/10000 [==============================] - 7s 692us/step - loss: 0.0240 - acc: 0.9901 - val_loss: 9.7350 - val_acc: 0.2889\n",
            "Epoch 19/75\n",
            "10000/10000 [==============================] - 7s 693us/step - loss: 0.0232 - acc: 0.9912 - val_loss: 9.5756 - val_acc: 0.2963\n",
            "Epoch 20/75\n",
            "10000/10000 [==============================] - 7s 694us/step - loss: 0.0300 - acc: 0.9906 - val_loss: 9.3047 - val_acc: 0.2959\n",
            "Epoch 21/75\n",
            "10000/10000 [==============================] - 7s 690us/step - loss: 0.0214 - acc: 0.9928 - val_loss: 10.0525 - val_acc: 0.2906\n",
            "Epoch 22/75\n",
            "10000/10000 [==============================] - 7s 695us/step - loss: 0.0234 - acc: 0.9915 - val_loss: 9.3847 - val_acc: 0.3054\n",
            "Epoch 23/75\n",
            "10000/10000 [==============================] - 7s 689us/step - loss: 0.0169 - acc: 0.9933 - val_loss: 9.8335 - val_acc: 0.3024\n",
            "Epoch 24/75\n",
            "10000/10000 [==============================] - 7s 693us/step - loss: 0.0198 - acc: 0.9927 - val_loss: 9.7457 - val_acc: 0.2959\n",
            "Epoch 25/75\n",
            "10000/10000 [==============================] - 7s 694us/step - loss: 0.0214 - acc: 0.9930 - val_loss: 9.7334 - val_acc: 0.3015\n",
            "Epoch 26/75\n",
            "10000/10000 [==============================] - 7s 696us/step - loss: 0.0159 - acc: 0.9950 - val_loss: 9.7925 - val_acc: 0.2941\n",
            "Epoch 27/75\n",
            "10000/10000 [==============================] - 7s 693us/step - loss: 0.0194 - acc: 0.9933 - val_loss: 9.8759 - val_acc: 0.2967\n",
            "Epoch 28/75\n",
            "10000/10000 [==============================] - 7s 693us/step - loss: 0.0159 - acc: 0.9941 - val_loss: 9.8584 - val_acc: 0.3033\n",
            "Epoch 29/75\n",
            "10000/10000 [==============================] - 7s 693us/step - loss: 0.0174 - acc: 0.9940 - val_loss: 9.9572 - val_acc: 0.2967\n",
            "Epoch 30/75\n",
            "10000/10000 [==============================] - 7s 694us/step - loss: 0.0156 - acc: 0.9949 - val_loss: 9.4425 - val_acc: 0.3037\n",
            "Epoch 31/75\n",
            "10000/10000 [==============================] - 7s 693us/step - loss: 0.0146 - acc: 0.9951 - val_loss: 9.6770 - val_acc: 0.3054\n",
            "Epoch 32/75\n",
            "10000/10000 [==============================] - 7s 691us/step - loss: 0.0113 - acc: 0.9951 - val_loss: 9.8487 - val_acc: 0.3033\n",
            "Epoch 33/75\n",
            "10000/10000 [==============================] - 7s 693us/step - loss: 0.0142 - acc: 0.9945 - val_loss: 9.9571 - val_acc: 0.3028\n",
            "Epoch 34/75\n",
            "10000/10000 [==============================] - 7s 694us/step - loss: 0.0147 - acc: 0.9943 - val_loss: 9.9538 - val_acc: 0.3020\n",
            "Epoch 35/75\n",
            "10000/10000 [==============================] - 7s 691us/step - loss: 0.0128 - acc: 0.9962 - val_loss: 9.8795 - val_acc: 0.3098\n",
            "Epoch 36/75\n",
            "10000/10000 [==============================] - 7s 691us/step - loss: 0.0170 - acc: 0.9933 - val_loss: 9.7591 - val_acc: 0.3046\n",
            "Epoch 37/75\n",
            "10000/10000 [==============================] - 7s 694us/step - loss: 0.0136 - acc: 0.9960 - val_loss: 9.8896 - val_acc: 0.3054\n",
            "Epoch 38/75\n",
            "10000/10000 [==============================] - 7s 693us/step - loss: 0.0175 - acc: 0.9935 - val_loss: 9.6798 - val_acc: 0.3028\n",
            "Epoch 39/75\n",
            "10000/10000 [==============================] - 7s 696us/step - loss: 0.0133 - acc: 0.9959 - val_loss: 9.7829 - val_acc: 0.3054\n",
            "Epoch 40/75\n",
            "10000/10000 [==============================] - 7s 692us/step - loss: 0.0105 - acc: 0.9958 - val_loss: 9.7557 - val_acc: 0.3085\n",
            "Epoch 41/75\n",
            "10000/10000 [==============================] - 7s 690us/step - loss: 0.0131 - acc: 0.9950 - val_loss: 9.8843 - val_acc: 0.3142\n",
            "Epoch 42/75\n",
            "10000/10000 [==============================] - 7s 692us/step - loss: 0.0121 - acc: 0.9952 - val_loss: 10.1505 - val_acc: 0.3050\n",
            "Epoch 43/75\n",
            " 6272/10000 [=================>............] - ETA: 2s - loss: 0.0106 - acc: 0.9962"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTnk6-OzIK7m",
        "colab_type": "code",
        "outputId": "42ca8188-5744-4bd3-888f-5f1c3e57a930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 32, 32, 1024)      4096      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 32, 32, 1024)      0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32, 32, 512)       524800    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 32, 32, 512)       0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 32, 32, 128)       65664     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32, 32, 6)         774       \n",
            "=================================================================\n",
            "Total params: 595,334\n",
            "Trainable params: 595,334\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iVxdpsjHplv",
        "colab_type": "code",
        "outputId": "db7fd0b5-cb4d-4aa3-b5ba-938be38a1f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(32, 32,3)))\n",
        "model.add(Dense(16))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=75, validation_data=(X_test, y_test),shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3ed1ec109815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_subclassed_network\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_base_init\u001b[0;34m(self, name, trainable, dtype)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;34m'It looks like you are trying to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;34m'a version of multi-backend Keras that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;34m'does not support TensorFlow 2.0. We recommend '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYlw1es4KVv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    base_model = densenet.DenseNet121(input_shape=(32, 32, 3),\n",
        "                                     #weights='imagenet',\n",
        "                                     include_top=False,\n",
        "                                     pooling='avg')\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Dense(1000, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dense(500, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dense(150, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlaSSb4dKVkB",
        "colab_type": "code",
        "outputId": "b9ebeef0-d49f-408d-a8f4-66ae81874d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = build_model()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 38, 38, 3)    0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 16, 16, 64)   9408        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 16, 16, 64)   0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 18, 18, 64)   0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 8, 8, 64)     0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 8, 8, 64)     256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 8, 8, 64)     0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 128)    8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 8, 128)    0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 8, 8, 96)     0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 8, 8, 96)     384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 8, 8, 96)     0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 128)    12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 8, 128)    0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 8, 8, 128)    0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 8, 8, 128)    0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 128)    16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 8, 128)    0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 8, 8, 160)    0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 8, 8, 160)    640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 8, 8, 160)    0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 8, 8, 128)    20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 8, 8, 128)    0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 8, 8, 192)    0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 8, 8, 192)    768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 8, 8, 192)    0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 8, 8, 128)    24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 8, 8, 128)    0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 8, 8, 224)    0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 8, 8, 224)    896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 8, 8, 224)    0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 8, 8, 128)    28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 8, 8, 128)    0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 8, 8, 256)    0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 8, 8, 256)    1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 8, 8, 256)    0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 8, 8, 128)    32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 4, 4, 128)    0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 4, 4, 128)    512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 4, 4, 128)    0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 4, 4, 160)    0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 4, 4, 160)    640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 4, 4, 160)    0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 4, 4, 192)    0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 4, 4, 192)    768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 4, 4, 192)    0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 4, 4, 224)    0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 4, 4, 224)    896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 4, 4, 224)    0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 4, 4, 256)    0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 4, 4, 256)    1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 4, 4, 256)    0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 4, 4, 128)    32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 4, 4, 128)    0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 4, 4, 288)    0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 4, 4, 288)    1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 4, 4, 288)    0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 4, 4, 128)    36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 4, 4, 128)    0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 4, 4, 320)    0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 4, 4, 320)    1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 4, 4, 320)    0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 4, 4, 128)    40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 4, 4, 128)    0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 4, 4, 352)    0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 4, 4, 352)    1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 4, 4, 352)    0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 4, 4, 128)    45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 4, 4, 128)    0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 4, 4, 384)    0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 4, 4, 384)    1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 4, 4, 384)    0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 4, 4, 128)    49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 4, 4, 128)    0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 4, 4, 416)    0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 4, 4, 416)    1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 4, 4, 416)    0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 4, 4, 128)    53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 4, 4, 448)    0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 4, 4, 448)    1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 4, 4, 448)    0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 4, 4, 128)    57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 4, 4, 480)    0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 4, 4, 480)    1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 4, 4, 480)    0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 4, 4, 128)    61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 4, 4, 512)    0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 4, 4, 512)    2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 4, 4, 512)    0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 4, 4, 256)    131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 2, 2, 256)    0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 2, 2, 256)    1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 2, 2, 256)    0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 128)    32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 2, 2, 128)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 2, 2, 288)    0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 2, 2, 288)    1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 2, 2, 288)    0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 128)    36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 2, 2, 128)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 2, 2, 320)    0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 2, 2, 320)    1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 2, 2, 320)    0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 128)    40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 2, 2, 128)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 2, 2, 352)    0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 2, 2, 352)    1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 2, 2, 352)    0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 128)    45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 2, 2, 128)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 2, 2, 384)    0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 2, 2, 384)    1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 2, 2, 384)    0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 128)    49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 2, 2, 128)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 2, 2, 416)    0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 2, 2, 416)    1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 2, 2, 416)    0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 128)    53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 2, 2, 128)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 2, 2, 448)    0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 2, 2, 448)    1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 2, 2, 448)    0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 2, 2, 128)    57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 2, 2, 128)    0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 2, 2, 480)    0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 2, 2, 480)    1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 2, 2, 480)    0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 2, 2, 128)    61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 2, 2, 128)    0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 2, 2, 512)    0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 2, 2, 512)    2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 2, 2, 512)    0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 2, 2, 128)    65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 2, 2, 128)    512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 2, 2, 128)    0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 2, 2, 32)     36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 2, 2, 544)    0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 2, 2, 544)    2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 2, 2, 544)    0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 2, 2, 128)    69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 2, 2, 576)    0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 2, 2, 576)    2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 2, 2, 576)    0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 2, 2, 128)    73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 2, 2, 608)    0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 2, 2, 608)    2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 2, 2, 608)    0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 2, 2, 128)    77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 2, 2, 640)    0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 2, 2, 640)    2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 2, 2, 640)    0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 2, 2, 128)    81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 2, 2, 672)    0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 2, 2, 672)    2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 2, 2, 672)    0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 2, 2, 128)    86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 2, 2, 704)    0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 2, 2, 704)    2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 2, 2, 704)    0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 2, 2, 128)    90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 2, 2, 736)    0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 2, 2, 736)    2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 2, 2, 736)    0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 2, 2, 128)    94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 2, 2, 768)    0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 2, 2, 768)    3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 2, 2, 768)    0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 2, 2, 128)    98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 2, 2, 800)    0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 2, 2, 800)    3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 2, 2, 800)    0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 2, 2, 128)    102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 2, 2, 832)    0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 2, 2, 832)    3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 2, 2, 832)    0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 2, 2, 128)    106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 2, 2, 864)    0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 2, 2, 864)    3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 2, 2, 864)    0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 2, 2, 128)    110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 2, 2, 896)    0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 2, 2, 896)    3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 2, 2, 896)    0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 2, 2, 128)    114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 2, 2, 928)    0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 2, 2, 928)    3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 2, 2, 928)    0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 2, 2, 128)    118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 2, 2, 960)    0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 2, 2, 960)    3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 2, 2, 960)    0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 2, 2, 128)    122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 2, 2, 992)    0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 2, 2, 992)    3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 2, 2, 992)    0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 2, 2, 128)    126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 2, 2, 128)    512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 2, 2, 128)    0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 2, 2, 32)     36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 2, 2, 1024)   0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 2, 2, 1024)   4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 2, 2, 1024)   0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 2, 2, 512)    524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 1, 1, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 1, 1, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 1, 1, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 1, 1, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 1, 1, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 1, 1, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 1, 1, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 1, 1, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 1, 1, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 1, 1, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 1, 1, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 1, 1, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 1, 1, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 1, 1, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 1, 1, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 1, 1, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 1, 1, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 1, 1, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 1, 1, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 1, 1, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 1, 1, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 1, 1, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 1, 1, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 1, 1, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 1, 1, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 1, 1, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 1, 1, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 1, 1, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 1, 1, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 1, 1, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 1, 1, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 1, 1, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 1, 1, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 1, 1, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 1, 1, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 1, 1, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 1, 1, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 1, 1, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 1, 1, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 1, 1, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 1, 1, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 1, 1, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 1, 1, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 1, 1, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 1, 1, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 1, 1, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 1, 1, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 1, 1, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 1, 1, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 1, 1, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 1, 1, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 1, 1, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 1, 1, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 1, 1, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 1, 1, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 1, 1, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 1, 1, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 1, 1, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 1, 1, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 1, 1, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 1, 1, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 1, 1, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 1, 1, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 1, 1, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 1, 1, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 1, 1, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 1, 1, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 1, 1, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 1, 1, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 1, 1, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 1, 1, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 1, 1, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 1, 1, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 1, 1, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 1, 1, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 1, 1, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 1, 1, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 1, 1, 1024)   0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 1000)         1025000     avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 1000)         0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_613 (Activation)     (None, 1000)         0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 500)          500500      activation_613[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 500)          0           dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_614 (Activation)     (None, 500)          0           dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 150)          75150       activation_614[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 150)          0           dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_615 (Activation)     (None, 150)          0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 10)           1510        activation_615[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 8,639,664\n",
            "Trainable params: 8,556,016\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVaGuPDLKpV7",
        "colab_type": "code",
        "outputId": "75f20961-94c9-44cf-ac3a-768a4b6f0c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=75, validation_data=(X_test, y_test),shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30000 samples, validate on 2295 samples\n",
            "Epoch 1/75\n",
            " 6528/30000 [=====>........................] - ETA: 3:52 - loss: 192.0089 - acc: 0.1055"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-f195f53ad930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUsPxd_UUGeS",
        "colab_type": "code",
        "outputId": "7c5ed8dd-7d1d-427f-f31a-1354440230d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "accuracy = history.history['acc']\n",
        "val_accuracy = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_3aYo7EZRSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeCHdgPrAgZG",
        "colab_type": "code",
        "outputId": "b11f8486-391e-49f7-8f04-dd834ef89f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# define input sequence\n",
        "\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "  \n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6e5f38e3f77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_subclassed_network\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_base_init\u001b[0;34m(self, name, trainable, dtype)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;34m'It looks like you are trying to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;34m'a version of multi-backend Keras that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;34m'does not support TensorFlow 2.0. We recommend '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqZptrw8AiYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}